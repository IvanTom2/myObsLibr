Коэффициент корреляции - это метрика, которая отражает связанность двух переменных. Суть его в том, что если значение одной переменной увеличивается, то значение другой переменной движется пропорционально (или обратно пропорционально). Коэффициент корреляции находится между -1 и 1. Если коэффициент корреляции между переменными 0, то, скорее всего, они никак между собой не связаны.

Коэффициент корреляции является полезной метрикой, но он имеет недостатки. Например, если связь между переменными нелинейна, то коэффициент корреляции может ее не распознать (например, налоги - в определенной точке налоговой ставки население начинает уклоняться от налогов, вследствие чего связь налоговых поступлений и налоговой ставки меняет свое направление). 

Корреляция не объясняет взаимосвязь переменных. С помощью ее можно лишь заметить эту взаимосвязь, да и то не факт, что переменные связаны между собой - взаимосвязь может быть обусловлена случайностью. Стоит заметить, если долго и упорно искать корреляцию между разными переменными, то рано или поздно она будет найдена. 

Один из самых популярных коэффициентов корреляции - коэффициент корреляции Пирсона.
$$r_{xy}=\frac{\sum_{i=1}^{n}(x_{i}-\overline{x})(y_i-\overline{y}))}{(n-1)s_{x}s_{y}}$$
Помимо коэффициента корреляции Пирсона, существуют и другие. Например, кф корреляции Спирмена или кф корреляции Кенделла. Оба коэффициента корреляции являются ранговыми, т.е. основываются на номерах наблюдений в наборе данных. Т.к. они работают с рангами, а не с самими значениями, то они устойчивы к выбросам и даже некоторым видам нелинейности. 
___
Links: [[Статистика]] [[Теория вероятностей и математическая статистика]]
Tags:
References: