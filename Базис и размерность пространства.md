Пусть $L$ - это линейное пространство над $\mathbb{R}$. $x_1, x_2, ..., x_n \in L$, $\alpha_1, \alpha_2, ..., \alpha_n \in \mathbb{R}$. 
Вектора $\alpha_1 x_1 + \alpha_2 x_2 + ... + \alpha_n x_n$ - ***линейная комбинация векторов***. При этом $\alpha_i$ - это ***коэффициенты***.

Конечная сумма векторов называется ***линейно зависимой***, если существуют $\alpha_i$ такие, чтобы не все были равны нули и удовлетворяли равенству:
$\alpha_1 x_1 + \alpha_2 x_2 + ... + \alpha_n x_n=\vec{0}$ 
Если же из этого равенства следует, что $\forall i \ \alpha_i=0$, то система из векторов $x_i$ называется ***линейно независимой***. Бесконечная система векторов называется линейно зависимой, если в ней существует конечная линейно зависимая подсистема. 

***Лемма 1***. Система векторов линейно зависима $\leftrightarrow$ один из них линейно выражается через остальные (является их линейной комбинацией).
***Лемма 2***. Система векторов линейно зависима $\leftrightarrow$ какой-либо из них линейно выражается через предыдущие. 

Система векторов $e_1, e_2, e_n$ называется ***базой*** линейного пространства $L$, если она линейно независима и любой вектор $x \in L$ линейно выражается через $e_1, e_2, e_n$. 
Из леммы 1 следует, что база - это максимальная линейно независимая система. Если в пространстве существует конечная база, то такое пространство называется ***конечномерным***. 

***Теорема***. Все базы в конечномерном линейном пространстве $L$ состоят из одного и того же числа векторов. Это число называется ***размерностью*** пространства $L$. 

База линейного пространства, записанная в определенном порядке, называется ***базисом*** (***координатной системой***). Если $e_1, e_2, e_n$ - базис в $L$, $x$ - произвольный элемент $x$, то $x$ можно представить в виде линейной комбинации - ***разложить по базису***:
$x=\alpha_1 e_1 + \alpha_2 e_2 + \alpha_n e_n$
***Разложение по базису единственно***. 

Числа $\alpha_1, \alpha_2, \alpha_n$ называются ***координатами*** вектора $x$ в базисе $e_1, e_2, e_n$. Координатная строка вектора $x$ записывается следующим образом:
$[x]_e=(\alpha_1, \alpha_2, \alpha_n)$

Связь координат вектора $x$ между базисами описывается ***матрицей перехода***. Пусть $e_1, e_2, e_n$ - исходный базис, а $e_{1}^{'}, e_{2}^{'}, e_{n}^{'}$ другой базис в $L$. Каждый из векторов $e_{i}^{'}$ можно разложить по базису $e_1, e_2, e_n$:
$\begin{eqnarray} e_{1}^{'} = s_{11}e_1 + s_{12}e_2 + s_{1n}e_n \\ e_{2}^{'} = s_{21}e_1 + s_{22}e_2 + s_{2n}e_n \\ e_{n}^{'} = s_{n1}e_1 + s_{n2}e_2 + s_{nn}e_n \end{eqnarray}$

Матрица $S=(s_{ij})$ - это ***матрица перехода*** от базиса $e_1, e_2, e_n$ к $e_{1}^{'}, e_{2}^{'}, e_{n}^{'}$. 
***Теорема***. $\forall x \in L \quad [x]_e=[x]_e^{'} \cdot S$
***Следствие***. Матрицей обратного перехода от $e_{1}^{'}, e_{2}^{'}, e_{n}^{'}$ к $e_1, e_2, e_n$ является $S^{-1}$. ***Матрица перехода всегда невырождена***. 

___
Relations: [[Линейное векторное пространство]] 
Tags: #theory 
References: [[Линейная алгебра и аналитическая геометрия Киркинский]] 
Query: 